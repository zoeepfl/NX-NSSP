{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini project 1, group AM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of content\n",
    "<!-- [1. Data Preparation](#1.-Data-Preparation)  \n",
    "[2. Analysis](#2.-Analysis)  \n",
    "[3. Results](#3.-Results)  -->\n",
    "\n",
    "[Imports](#imports)\n",
    "\n",
    "[Part 1](#1)\n",
    "- [1) Structural preprocessing](#structural-preprocessing)\n",
    "   - [a) Skull-stripping](#a-skull-stripping)\n",
    "   - [b) Segmentation](#b-segmentation)\n",
    "- [2) Functional preprocessing](#functional-preprocessing)\n",
    "   - [a) Concatenation](#a-concatenation)\n",
    "   - [b) Motion correction](#b-motion-correction)\n",
    "   - [c) Co-registration (bonus)](#c-co-registration-(bonus))\n",
    "   - [d) Gaussian smoothing](#d-gaussian-smoothing)\n",
    "- [3) Experimental design matrix](#experimental-design-matrix)\n",
    "- [4) GLM analysis](#glm-analysis)\n",
    "- [5) Activation maps](#activation-maps)\n",
    "- [6) Atlas overlay](#atlas-overlay)\n",
    "\n",
    "[Part 2 : Variant 3](#2)\n",
    "- [1) K-means clustering](#2-1)\n",
    "- [2) Selection of a number of clusters](#2-2)\n",
    "- [3) Pairwise similarity](#2-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui wx\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#####################\n",
    "# Import of utils.py functions\n",
    "#####################\n",
    "# Required to get utils.py and access its functions\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "sys.path.append('.')\n",
    "from utils import loadFSL, FSLeyesServer, mkdir_no_exist\n",
    "\n",
    "\n",
    "#############################\n",
    "# Loading fsl and freesurfer within Neurodesk\n",
    "# You can find the list of available other modules by clicking on the \"Softwares\" tab on the left\n",
    "#############################\n",
    "import lmod\n",
    "await lmod.purge(force=True)\n",
    "await lmod.load('fsl/6.0.7.4')\n",
    "await lmod.load('freesurfer/7.4.1')\n",
    "await lmod.list()\n",
    "\n",
    "####################\n",
    "# Setup FSL path\n",
    "####################\n",
    "loadFSL()\n",
    "\n",
    "###################\n",
    "# Load all relevant libraries for the lab\n",
    "##################\n",
    "import fsl.wrappers\n",
    "from fsl.wrappers import fslmaths\n",
    "\n",
    "import mne_nirs\n",
    "import nilearn\n",
    "from nilearn.datasets import fetch_development_fmri\n",
    "\n",
    "import mne\n",
    "import mne_nirs\n",
    "import dipy\n",
    "from dipy.data import fetch_bundles_2_subjects, read_bundles_2_subjects\n",
    "import xml.etree.ElementTree as ET\n",
    "import os.path as op\n",
    "import nibabel as nib\n",
    "import glob\n",
    "\n",
    "import ants\n",
    "\n",
    "import openneuro\n",
    "from mne.datasets import sample\n",
    "from mne_bids import BIDSPath, read_raw_bids, print_dir_tree, make_report\n",
    "\n",
    "\n",
    "# Useful imports to define the direct download function below\n",
    "import requests\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# FSL function wrappers which we will call from python directly\n",
    "from fsl.wrappers import fast, bet\n",
    "from fsl.wrappers.misc import fslroi\n",
    "from fsl.wrappers import flirt\n",
    "from fsl.wrappers import mcflirt\n",
    "\n",
    "# General purpose imports to handle paths, files etc\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import subprocess\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Structural preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)a) Skull-stripping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "anatomical_path = op.join(\"subject101410\", \"T1w\", \"T1w.nii.gz\") #the original brain\n",
    "subject_id = '101410'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivatives will be written to: /data/NX-NSSP/derivatives/preprocessed_data/subject_101410\n"
     ]
    }
   ],
   "source": [
    "derivatives = op.join(\"derivatives\", \"preprocessed_data\", \"subject_101410\")\n",
    "deriv_anat = op.join(derivatives, \"anat\")\n",
    "deriv_func = op.join(derivatives, \"func\")\n",
    "\n",
    "for d in (deriv_anat, deriv_func):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(\"Derivatives will be written to:\", os.path.abspath(derivatives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bids_root   = \"/data/NX-NSSP\"  \n",
    "#preproc_root = op.join(bids_root, 'derivatives','preprocessed_data')\n",
    "#deriv_root = op.join(bids_root, 'derivatives')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:52:04: Debug: Adding duplicate image handler for 'Windows bitmap file'\n",
      "08:52:04: Debug: Adding duplicate animation handler for '1' type\n",
      "08:52:04: Debug: Adding duplicate animation handler for '2' type\n",
      "08:52:04: Debug: Adding duplicate image handler for 'Windows bitmap file'\n",
      "08:52:04: Debug: Adding duplicate animation handler for '1' type\n",
      "08:52:04: Debug: Adding duplicate animation handler for '2' type\n",
      "\n",
      "(ipykernel_launcher.py:3627): Gtk-CRITICAL **: 08:52:04.426: gtk_window_resize: assertion 'height > 0' failed\n"
     ]
    }
   ],
   "source": [
    "fsleyesDisplay = FSLeyesServer()\n",
    "fsleyesDisplay.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(ipykernel_launcher.py:3627): Gdk-WARNING **: 08:52:08.432: gdkdrawable-x11.c:952 drawable is not a pixmap or window\n"
     ]
    }
   ],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(anatomical_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skull_stripped_anatomical(deriv_anat, anatomical_path, subject_id, robust=False):\n",
    "    \"\"\"\n",
    "    Function to perform skull-stripping (removing the skull around the brain).\n",
    "    This is a simple wrapper around the brain extraction tool (BET) in FSL's suite\n",
    "    It assumes data to be in the BIDS format (which we will cover in the following weeks).\n",
    "    The method also saves the brain mask which was used to extract the brain.\n",
    "\n",
    "    The brain extraction is conducted only on the T1w of the participant.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    subject_id: string\n",
    "        Subject ID, the subject on which brain extraction should be conducted.\n",
    "    robust: bool\n",
    "        Whether to conduct robust center estimation with BET or not. Default is False.\n",
    "    \"\"\"\n",
    "    # We perform here skull stripping (you'll learn more about it next week!).\n",
    "    # For now all you need to do is that we remove the bones and flesh from the MRI to get the brain!\n",
    "    betted_brain_path = op.join(deriv_anat, 'sub-{}_T1w'.format(subject_id))\n",
    "    os.system('bet {} {} -m {}'.format(anatomical_path, betted_brain_path, '-R' if robust else ''))\n",
    "    print(\"Done with BET.\")\n",
    "\n",
    "resulting_mask_path = op.join(deriv_anat, 'sub-101410_T1w_mask')\n",
    "get_skull_stripped_anatomical(deriv_anat, anatomical_path, subject_id, robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.load(resulting_mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_fsl_math_approach(img_path, mask_path, masked_img_path):\n",
    "    os.system('fslmaths {} -mas {} {}'.format(img_path, mask_path, masked_img_path))\n",
    "    \n",
    "betted_brain_path = op.join(deriv_anat, 'sub-101410_T1w.nii.gz') # The brain without skull is in the derivatives folder\n",
    "resulting_mask_path = op.join(deriv_anat, 'sub-101410_T1w_mask.nii.gz') # The mask to use\n",
    "\n",
    "apply_fsl_math_approach(anatomical_path, resulting_mask_path, betted_brain_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(betted_brain_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)b) Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_path = op.join(deriv_anat, 'sub-101410_T1w')\n",
    "fast_target = bet_path # Replace with either anatomical_path or bet_path (note: you can try both and decide which is more reasonable!)\n",
    "\n",
    "[os.remove(f) for f in glob.glob(op.join(deriv_anat, '*fast*'))] # Just to clean the directory in between runs of the cell\n",
    "segmentation_path = op.join(deriv_anat, 'sub-101410_T1w_fast')\n",
    "fast(imgs=[fast_target], out=segmentation_path, n_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pve_0 in red : CSF \\\n",
    "pve_1 in green : grey matter \\\n",
    "pve_2 in blue : white matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(bet_path)\n",
    "fsleyesDisplay.load(glob.glob(op.join(deriv_anat,'*pve_0*'))[0])\n",
    "fsleyesDisplay.load(glob.glob(op.join(deriv_anat,'*pve_1*'))[0])\n",
    "fsleyesDisplay.load(glob.glob(op.join(deriv_anat,'*pve_2*'))[0])\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[1]).cmap = 'Red'\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[2]).cmap = 'Green'\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[3]).cmap = 'Blue'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Functional preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)a) Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining size in derivatives folder: 953.60 MB\n"
     ]
    }
   ],
   "source": [
    "# Code to verify folder size\n",
    "total_size = sum(os.path.getsize(op.join(deriv_func, f)) for f in os.listdir(deriv_func))\n",
    "print(f\"Remaining size in derivatives folder: {total_size / (1024**2):.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functional paths have been created\n"
     ]
    }
   ],
   "source": [
    "# Create functional paths\n",
    "functional_path_LR = op.join('subject101410', 'fMRI', 'tfMRI_MOTOR_LR', 'tfMRI_MOTOR_LR.nii') \n",
    "functional_path_RL = op.join('subject101410', 'fMRI', 'tfMRI_MOTOR_RL', 'tfMRI_MOTOR_RL.nii') \n",
    "\n",
    "print(\"Functional paths have been created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing variance for LR run\n",
      "Global variance for LR: 519161344.000000\n",
      "Scaling factor for LR: 4.388830677732065e-05\n",
      "Saved normalized LR run: derivatives/preprocessed_data/subject_101410/func/tfMRI_MOTOR_LR_varscaled.nii.gz\n",
      "\n",
      "Normalizing variance for RL run\n",
      "Global variance for RL: 519202016.000000\n",
      "Scaling factor for RL: 4.3886587735293315e-05\n",
      "Saved normalized RL run: derivatives/preprocessed_data/subject_101410/func/tfMRI_MOTOR_RL_varscaled.nii.gz\n",
      "\n",
      "Concatenating normalized runs...\n",
      "Done! Final concatenated file: derivatives/preprocessed_data/subject_101410/func/sub-101410_motor_concat_varscaled.nii.gz\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Variance Normalisation - Run LR\n",
    "###########################################\n",
    "print(\"Normalizing variance for LR run\")\n",
    "\n",
    "# Calculate the variance for LR\n",
    "variance_LR = subprocess.check_output(['fslstats', functional_path_LR, '-V']).decode().split()[1]\n",
    "print(f\"Global variance for LR: {variance_LR}\")\n",
    "\n",
    "# Compute the scaling factor (1 / sqrt(variance))\n",
    "scale_LR = 1 / (float(variance_LR) ** 0.5)\n",
    "print(f\"Scaling factor for LR: {scale_LR}\")\n",
    "\n",
    "# Apply scaling to normalize the variance\n",
    "scaled_LR_path = op.join(deriv_func, 'tfMRI_MOTOR_LR_varscaled.nii.gz')\n",
    "subprocess.run(['fslmaths', functional_path_LR, '-mul', str(scale_LR), scaled_LR_path], check=True)\n",
    "print(f\"Saved normalized LR run: {scaled_LR_path}\\n\")\n",
    "\n",
    "# Delete intermediary variables to free memory\n",
    "del variance_LR, scale_LR\n",
    "gc.collect()\n",
    "\n",
    "###########################################\n",
    "# Variance Normalisation - Run RL\n",
    "###########################################\n",
    "print(\"Normalizing variance for RL run\")\n",
    "\n",
    "# Calculate the variance for RL\n",
    "variance_RL = subprocess.check_output(['fslstats', functional_path_RL, '-V']).decode().split()[1]\n",
    "print(f\"Global variance for RL: {variance_RL}\")\n",
    "\n",
    "# Compute the scaling factor for RL (1 / sqrt(variance))\n",
    "scale_RL = 1 / (float(variance_RL) ** 0.5)\n",
    "print(f\"Scaling factor for RL: {scale_RL}\")\n",
    "\n",
    "# Apply scaling to normalize the variance\n",
    "scaled_RL_path = op.join(deriv_func, 'tfMRI_MOTOR_RL_varscaled.nii.gz')\n",
    "subprocess.run(['fslmaths', functional_path_RL, '-mul', str(scale_RL), scaled_RL_path], check=True)\n",
    "print(f\"Saved normalized RL run: {scaled_RL_path}\\n\")\n",
    "\n",
    "# Delete intermediary variables to free memory\n",
    "del variance_RL, scale_RL\n",
    "gc.collect()\n",
    "\n",
    "###########################################\n",
    "# Concatenate the two runs\n",
    "###########################################\n",
    "print(\"Concatenating normalized runs...\")\n",
    "\n",
    "concat_path = op.join(deriv_func, f\"sub-{subject_id}_motor_concat_varscaled.nii.gz\")\n",
    "subprocess.run(['fslmerge', '-t', concat_path, scaled_LR_path, scaled_RL_path], check=True)\n",
    "\n",
    "print(f\"Done! Final concatenated file: {concat_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unnecessary files (RL and LR before concatanation)\n",
    "del scaled_LR_path, scaled_RL_path\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)b) Motion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the motion\n",
    "print(\"Starting the motion correction\")\n",
    "path_motioncorrected = op.join(deriv_func, 'tfMRI_MOTOR_motioncorrected') # path to the motion corrected file\n",
    "mcflirt(infile=concat_path, o=path_motioncorrected, plots=True, report=True, dof=6, mats=True)\n",
    "print(\"Motion corrected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display result\n",
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(concat_path)\n",
    "fsleyesDisplay.load(path_motioncorrected)\n",
    "print(\"Motion corrected done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mc_par_path = op.join(deriv_func, 'tfMRI_MOTOR_motioncorrected.par')\n",
    "\n",
    "def load_mot_params_fsl_6_dof(path):\n",
    "    return pd.read_csv(path, sep='  ', header=None, engine='python', names=['Rotation x', 'Rotation y', 'Rotation z','Translation x', 'Translation y', 'Translation z'])\n",
    "\n",
    "mot_params = load_mot_params_fsl_6_dof(mc_par_path)\n",
    "mot_params\n",
    "\n",
    "def compute_FD_power(mot_params):\n",
    "    framewise_diff = mot_params.diff().iloc[1:]\n",
    "\n",
    "    rotation_params = framewise_diff[['Rotation x', 'Rotation y', 'Rotation z']]\n",
    "    \n",
    "    convert_rot_to_arc = rotation_params*90                                    # transform from angle to arc of circle for a radius of 50mm, normal used values are 50 or 90 mm\n",
    "    translation_params = framewise_diff[['Translation x', 'Translation y', 'Translation z']]\n",
    "    fd = convert_rot_to_arc.abs().sum(axis=1) + translation_params.abs().sum(axis=1)\n",
    "    return fd\n",
    "\n",
    "fd = compute_FD_power(mot_params).to_numpy()\n",
    "threshold = np.quantile(fd,0.75) + 1.5*(np.quantile(fd,0.75) - np.quantile(fd,0.25))\n",
    "\n",
    "#%matplotlib inline\n",
    "plt.plot(list(range(1, fd.size+1)), fd)\n",
    "plt.xlabel('Volume')\n",
    "plt.ylabel('FD displacement (mm)')\n",
    "plt.hlines(threshold, 0, 370,colors='black', linestyles='dashed', label='FD threshold')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Indices of frames of motion above threshold: {(np.where(fd > threshold)[0] + 1).tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run fsl_motion_outliers to detect bad frames\n",
    "motion_no_outliers = f\"{path_motioncorrected}.nii.gz\"\n",
    "motion_outliers_confounds = op.join(deriv_func, 'motion_outliers_confounds.txt')\n",
    "motion_outliers_plot = op.join(deriv_func, 'motion_outliers_plot.png')\n",
    "motion_outliers_summary = op.join(deriv_func, 'motion_outliers_summary.txt')\n",
    "\n",
    "# Run fsl_motion_outliers command\n",
    "print(\"Running fsl_motion_outliers\")\n",
    "subprocess.run(f\"fsl_motion_outliers -i {motion_no_outliers} -o {motion_outliers_confounds} -p {motion_outliers_plot} -s {motion_outliers_summary} --fd --thresh=0.5\", shell=True)\n",
    "print(\"Motion outliers detection completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cell to run if save is not possible anymore\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_to_clear = \"derivatives/preprocessed_data/subject_101410\"\n",
    "if os.path.exists(folder_to_clear):\n",
    "     shutil.rmtree(folder_to_clear)\n",
    "     print(\"Dossier supprimé pour libérer de l'espace.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In order to determine how many in how many images the subject moves more than what is tolerated, we can run the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)c) Co-registration (bonus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions : (91, 109, 91, 568)\n",
      "(91, 109, 91)\n"
     ]
    }
   ],
   "source": [
    "#redefine the path if you have not run all the cells\n",
    "betted_brain_path = op.join(deriv_anat, 'sub-{}_T1w'.format(subject_id))\n",
    "concat_path = os.path.join(deriv_func, f\"sub-{subject_id}_motor_concat_varscaled.nii.gz\")\n",
    "\n",
    "#set reference = anatomical image and source fonctional image\n",
    "reference= betted_brain_path\n",
    "source= nib.load(concat_path)\n",
    "data_source = source.get_fdata()\n",
    "print(\"Dimensions :\", data_source.shape)\n",
    "\n",
    "#select on volume arbitrary \n",
    "volume_index = 10  \n",
    "volume_source = data_source[..., volume_index]\n",
    "print(volume_source.shape) \n",
    "\n",
    "#convert in tuple\n",
    "spacing = tuple(source.header.get_zooms()[:3])\n",
    "origin = tuple(source.affine[:3, 3])\n",
    "#Apply ANTS\n",
    "moving_image = ants.from_numpy(volume_source, origin=origin, spacing=spacing)\n",
    "fixed_image = ants.image_read(reference + '.nii.gz')\n",
    "\n",
    "transformation = ants.registration(fixed=fixed_image, moving=moving_image, type_of_transform = 'SyN' )\n",
    "warpedImage = ants.apply_transforms(fixed=fixed_image, moving=moving_image, transformlist=transformation['fwdtransforms'])\n",
    "\n",
    "# Save the image to disk\n",
    "resultAnts = op.join(deriv_anat,'sub-{}_T1w_mni_SyN.nii.gz'.format(subject_id))\n",
    "ants.image_write(warpedImage, resultAnts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the results functional overlay on anatomical\n",
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(reference) \n",
    "fsleyesDisplay.load(resultAnts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)d) Gaussian smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_path = concat_path\n",
    "cmd = 'fslmaths {} -s {} {}_smoothed-6mm'.format(output_path, 6/2.3548, output_path)\n",
    "subprocess.run(['fslmaths',output_path, '-s', str(6/2.3548), '{}_smoothed-6mm'.format(output_path)])\n",
    "results_smoothing = '{}_smoothed-6mm.nii.gz'.format(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(output_path) \n",
    "fsleyesDisplay.load(results_smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Experimental design matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level import make_first_level_design_matrix, FirstLevelModel\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "from nilearn.datasets import fetch_atlas_aal\n",
    "from nilearn.plotting import plot_stat_map\n",
    "from IPython.display import display\n",
    "from nilearn.image import mean_img\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fMRI_path = '/data/subject101410/fMRI'\n",
    "\n",
    "func_path_LR = op.join(fMRI_path, 'tfMRI_MOTOR_LR') \n",
    "func_path_RL = op.join(fMRI_path, 'tfMRI_MOTOR_RL') \n",
    "\n",
    "events_LR = pd.read_csv(op.join(func_path_LR, 'events_LR.csv'), sep=',')\n",
    "events_RL = pd.read_csv(op.join(func_path_RL, 'events_RL.csv'), sep=',')\n",
    "\n",
    "print(\"Events Table — LR Run\")\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)\n",
    "display(events_LR.head(10))\n",
    "\n",
    "print(\"Events Table — RL Run\")\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)\n",
    "display(events_RL.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nib.load(func_img)\n",
    "n_scans = img.shape[3]           # number of volumes\n",
    "TR = img.header.get_zooms()[3]   # repetition time\n",
    "frame_times = np.arange(n_scans) * TR  # time vector for each volume\n",
    "\n",
    "design_matrix = make_first_level_design_matrix(\n",
    "    frame_times,\n",
    "    events_RL,\n",
    "    hrf_model='spm',\n",
    "    drift_model='cosine',\n",
    "    high_pass=0.01)\n",
    "\n",
    "print('Design Matrix ')\n",
    "plot_design_matrix(fmri_glm_.design_matrices_[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) GLM analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLM_fMRI = FirstLevelModel(t_r=0.72,\n",
    "                           noise_model='ar1',\n",
    "                           standardize=False,\n",
    "                           hrf_model='spm',\n",
    "                           drift_model=None,\n",
    "                           high_pass=.01)\n",
    "\n",
    "# Fit the model to our design and data\n",
    "fmri_glm = GLM_fMRI.fit(fmri_img, events_LR)\n",
    "\n",
    "# Get regressors\n",
    "regressors = fmri_glm.design_matrices_[0].columns.tolist()\n",
    "print(regressors)\n",
    "regressors = fmri_glm.design_matrices_[0].columns.tolist()\n",
    "print(regressors)\n",
    "\n",
    "# Compute and plot t-map for each regressor and run\n",
    "for reg in regressors:\n",
    "    t_map = fmri_glm.compute_contrast(reg, output_type='stat')\n",
    "    plotting.plot_stat_map(\n",
    "        t_map,\n",
    "        threshold=3.0,\n",
    "        display_mode='ortho',\n",
    "        title=f'Statistical map: {reg}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments on t-map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Activation maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_vector_hand_vs_foot = [1, 1, -1, -1, 0, 0] # depend on the regressor list, might be changed\n",
    "\n",
    "activation_map = fmri_glm.compute_contrast(contrast_vector_hand_vs_foot,\n",
    "                                  output_type='effect_size')\n",
    "# activation map\n",
    "plotting.plot_stat_map(\n",
    "    activation_map\n",
    "    threshold=0.5,          # might need to be adjusted as needed\n",
    "    display_mode='ortho',\n",
    "    cut_coords=(0, 0, 0),   # might need to be adjusted as needed\n",
    "    title='Hand > Foot Activation Map'\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "#nib.save(activation_map, 'activation_map_hand_vs_foot.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Atlas overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "atlas = fetch_atlas_aal()\n",
    "\n",
    "plotting.plot_stat_map(\n",
    "    activation_map,\n",
    "    threshold=2.5,\n",
    "    display_mode='ortho',\n",
    "    title='Activation Map (Hand > Foot) with AAL Overlay',\n",
    "    cut_coords=(0, 0, 0)\n",
    ")\n",
    "\n",
    "plotting.plot_roi(\n",
    "    atlas.maps,\n",
    "    bg_img=activation_map,\n",
    "    alpha=0.3,\n",
    "    display_mode='ortho',\n",
    "    cut_coords=(0, 0, 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 : Variant 3\n",
    "## 1) K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fMRI_path = '/data/NX-NSSP/subject101410/fMRI'\n",
    "# func_path_LR = op.join(fMRI_path, 'tfMRI_MOTOR_LR') \n",
    "# func_path_RL = op.join(fMRI_path, 'tfMRI_MOTOR_RL') \n",
    "\n",
    "img = nib.load('derivatives/preprocessed_data/subject_101410/func/sub-101410_motor_concat_varscaled.nii.gz')\n",
    "#Loading data\n",
    "# img = nib.load(op.join(func_path_LR,'tfMRI_MOTOR_LR.nii'))\n",
    "affine = img.affine\n",
    "data = np.asanyarray(img.dataobj)\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "\n",
    "# Make variables:\n",
    "# 'vol_shape' for shape of volumes\n",
    "# 'n_vols' for number of volumes\n",
    "# YOUR CODE HERE\n",
    "vol_shape = data.shape[:3]\n",
    "n_vols    = data.shape[3]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Note: In our case the background is encoded as 0 \n",
    "# you can consider that the first volume's background \n",
    "# voxels are the same as all following volumes\n",
    "\n",
    "slice_non_background = data[..., 0] != 0\n",
    "# Vectorize : Taking only non-zero voxels into a vector \n",
    "# (NOTE: that the order is important)\n",
    "samples = data[slice_non_background, :]\n",
    "\n",
    "# Calculate the mean across columns\n",
    "spatial_means = samples.mean(axis=1, keepdims=True)   # shape: (n_vols, 1)\n",
    "\n",
    "# Row means copied n_vols times so that we substract for each timepoint the spatial mean\n",
    "row_means = np.repeat(spatial_means, samples.shape[1], axis=1) # shape: (n_vols, n_voxels)\n",
    "\n",
    "# Subtract the means for each row, put the result into X\n",
    "X_kmeans = samples - row_means\n",
    "\n",
    "# Verify that the spatial mean behaves as expected after substraction\n",
    "print(\"Mean after centering (should be ~0):\", np.mean(X_kmeans, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kmeans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "max_nb_clusters = 10\n",
    "avg_dist_samples = []\n",
    "for nb_cluster in range(1, max_nb_clusters):\n",
    "    kmeans = KMeans(n_clusters=nb_cluster, random_state=0, n_init=\"auto\").fit(X_kmeans.T)\n",
    "    avg_dist_samples.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Selection of a number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(7,5))\n",
    "\n",
    "ax.plot(np.arange(1, len(avg_dist_samples)+1), avg_dist_samples, label='explained variance ratios', c='k')\n",
    "\n",
    "ax.set_xlabel('Clusters #', size=15)\n",
    "ax.legend(prop={'size':15})\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "nb_clusters = 2 # The number of clusters you want\n",
    "kmeans = KMeans(n_clusters=nb_cluster, random_state=0, n_init=\"auto\").fit(X_kmeans.T)\n",
    "\n",
    "kmeans_clusters = [] # List of spatial components (you should have in the list volumes)\n",
    "for i in range(nb_clusters):\n",
    "    centroid_3d = np.zeros(vol_shape)         # full 3D shape\n",
    "    centroid_3d[slice_non_background] = kmeans.cluster_centers_[i]\n",
    "    kmeans_clusters.append(centroid_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_stat_map\n",
    "from nilearn.image import mean_img\n",
    "mean_img_ = mean_img(img)\n",
    "visual_idx = 0\n",
    "plot_stat_map(nib.Nifti1Image(kmeans_clusters[visual_idx], affine), bg_img=mean_img_, threshold=0,\n",
    "               cut_coords=[49,37,00], black_bg=True,\n",
    "              title=f'K-means Cluster {visual_idx}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_img_ = mean_img(img)\n",
    "zmax = vol_shape[2] - 1\n",
    "cut_coords = list(np.linspace(0, zmax, 9, dtype=int))  # 9 axial slices\n",
    "\n",
    "for i, centroid in enumerate(kmeans_clusters):\n",
    "    print(f\"Cluster {i+1}\")\n",
    "    plot_stat_map(\n",
    "        nib.Nifti1Image(centroid, affine),\n",
    "        bg_img=mean_img_,\n",
    "        display_mode='z',\n",
    "        cut_coords=cut_coords,\n",
    "        threshold=0,\n",
    "        colorbar=True,\n",
    "        black_bg=True,\n",
    "        title=f\"K-means Cluster {i+1}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Pairwise similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clusters = 5\n",
    "kmeans = KMeans(n_clusters=nb_clusters, random_state=0, n_init=\"auto\").fit(X_kmeans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# cluster_centers_: shape (5, n_voxels)\n",
    "C = kmeans.cluster_centers_\n",
    "\n",
    "m = 5\n",
    "sim = np.zeros((m, m))\n",
    "\n",
    "for i in range(m):\n",
    "    for j in range(m):\n",
    "        sim[i, j] = pearsonr(C[i], C[j])[0]  # correlation coefficient\n",
    "\n",
    "print(\"Similarity matrix (Pearson):\")\n",
    "print(np.round(sim, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
